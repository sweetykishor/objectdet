# -*- coding: utf-8 -*-
"""ObjectDetection.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aTkG14ZEzeBC9vo2bCsfbu7KPj9iBQpE
"""

import numpy as np
import matplotlib.pyplot as plt
import PIL.Image, PIL.ImageFont, PIL.ImageDraw
import tensorflow as tf
import tensorflow_datasets as tfds
import os

im_width = 75
im_height = 75
use_normalized_coordinates = True

def draw_bounding_boxes_on_image_array(image, boxes, color=[], thickness=1, display_str_list=()):

    if image.ndim == 3 and image.shape[2] == 1:
        image = image.squeeze(axis=2)
    image_pil = PIL.Image.fromarray(image)
    rgbimg = PIL.Image.new("RGBA", image_pil.size)
    rgbimg.paste(image_pil)
    draw_bounding_boxes_on_image(rgbimg, boxes, color, thickness, display_str_list)
    return np.array(rgbimg)

def draw_bounding_boxes_on_image(image, boxes, color=[], thickness=1, display_str_list=()):
    boxes_shape = boxes.shape
    if not boxes_shape:
        return
    if len(boxes_shape) != 2 or boxes_shape[1] != 4:
        raise ValueError("Input must be of size [N,4]")
    for i in range(boxes_shape[0]):
        draw_bounding_box_on_image(image, boxes[i, 1], boxes[i, 0], boxes[i, 3], boxes[i, 2],
                                   color[i], thickness, display_str_list[i])

def draw_bounding_box_on_image(image, ymin, xmin, ymax, xmax, color="red", thickness=1, display_str_list=None, use_normalized_coordinates=True):
    draw = PIL.ImageDraw.Draw(image)
    im_width, im_height = image.size
    if use_normalized_coordinates:
        (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)
    else:
        (left, right, top, bottom) = (xmin, xmax, ymin, ymax)
    draw.line([(left, top), (left, bottom), (right, bottom), (right, top), (left, top)],
              width=thickness, fill=color)

def dataset_to_numpy_util(training_dataset, validation_dataset, N):

    batch_train_ds = training_dataset.unbatch().batch(N)
    if tf.executing_eagerly():
        for validation_digits, (validation_labels, validation_bboxes) in validation_dataset:
            validation_digits = validation_digits.numpy()
            validation_labels = validation_labels.numpy()
            validation_bboxes = validation_bboxes.numpy()
            break
        for training_digits, (training_labels, training_bboxes) in training_dataset:
            training_digits = training_digits.numpy()
            training_labels = training_labels.numpy()
            training_bboxes = training_bboxes.numpy()
            break

    validation_labels = np.argmax(validation_labels, axis=1) + 1
    training_labels = np.argmax(training_labels, axis=1) + 1
    return (training_digits, training_labels, training_bboxes,
            validation_digits, validation_labels, validation_bboxes)


def read_image_tfds(image, label):

    xmin = tf.random.uniform((), 0, 75 - 28 + 1, dtype=tf.int32)
    ymin = tf.random.uniform((), 0, 75 - 28 + 1, dtype=tf.int32)
    image = tf.reshape(image, (28, 28, 1))
    image = tf.image.pad_to_bounding_box(image, ymin, xmin, 75, 75)
    image = tf.cast(image, tf.float32) / 255.0

    xmin = tf.cast(xmin, tf.float32)
    ymin = tf.cast(ymin, tf.float32)
    xmax = (xmin + 28) / 75
    ymax = (ymin + 28) / 75
    xmin = xmin / 75
    ymin = ymin / 75

    return image, (tf.one_hot(label - 1, 26), [xmin, ymin, xmax, ymax])

def get_training_dataset():
    dataset = tfds.load("emnist/letters", split="train", as_supervised=True, download=True)
    dataset = dataset.map(read_image_tfds, num_parallel_calls=16)
    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)
    dataset = dataset.repeat()
    dataset = dataset.batch(64, drop_remainder=True)
    dataset = dataset.prefetch(-1)
    return dataset

def get_validation_dataset():
    dataset = tfds.load("emnist/letters", split="train", as_supervised=True, download=True)
    dataset = dataset.map(read_image_tfds, num_parallel_calls=16)
    dataset = dataset.batch(10000, drop_remainder=True)
    dataset = dataset.repeat()
    return dataset

training_dataset = get_training_dataset()
validation_dataset = get_validation_dataset()
(training_digits, training_labels, training_bboxes,
 validation_digits, validation_labels, validation_bboxes) = dataset_to_numpy_util(training_dataset, validation_dataset, 10)

def feature_extractor(inputs):
    x = tf.keras.layers.Conv2D(16, activation="relu", kernel_size=3, input_shape=(75,75,1))(inputs)
    x = tf.keras.layers.AveragePooling2D((2,2))(x)
    x = tf.keras.layers.Conv2D(32, activation="relu", kernel_size=3)(x)
    x = tf.keras.layers.AveragePooling2D((2,2))(x)
    x = tf.keras.layers.Conv2D(64, activation="relu", kernel_size=3)(x)
    x = tf.keras.layers.AveragePooling2D((2,2))(x)
    return x

def dense_layers(inputs):
    x = tf.keras.layers.Flatten()(inputs)
    x = tf.keras.layers.Dense(128, activation="relu")(x)
    return x

def classifier(inputs):
    classification_output = tf.keras.layers.Dense(26, activation="softmax", name="classification")(inputs)
    return classification_output

def bounding_box_regression(inputs):
    bounding_box_regression_output = tf.keras.layers.Dense(4, name="bounding_box")(inputs)
    return bounding_box_regression_output

def final_model(inputs):
    feature_cnn = feature_extractor(inputs)
    dense_output = dense_layers(feature_cnn)
    classification_output = classifier(dense_output)
    bounding_box_output = bounding_box_regression(dense_output)
    model = tf.keras.Model(inputs=inputs, outputs=[classification_output, bounding_box_output])
    return model

def define_and_compile_model(inputs):
    model = final_model(inputs)
    model.compile(optimizer="adam",
                  loss={"classification": "categorical_crossentropy",
                        "bounding_box": "mse"},
                  metrics={"classification": "accuracy",
                           "bounding_box": "mse"})
    return model

inputs = tf.keras.layers.Input(shape=(75,75,1))
model = define_and_compile_model(inputs)
model.summary()

EPOCHS = 3
steps_per_epoch = 60000 // 64

history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch,
                    validation_data=validation_dataset, validation_steps=1, epochs=EPOCHS)
loss, classification_loss, bounding_box_loss, classification_acc, bounding_box_mse = model.evaluate(validation_dataset, steps=1)
print("\n--------------------\n")
print("Validation Accuracy: ", classification_acc)
print("\n--------------------\n")

def plot_metrics(metric_name, title):
    plt.title(title)
    plt.plot(history.history[metric_name], 'o-', color="blue", label=metric_name)
    plt.plot(history.history["val_" + metric_name], 'o-', color="green", label="val_" + metric_name)
    plt.legend()
    plt.show()

plot_metrics("bounding_box_mse", "Bounding Box MSE")
plot_metrics("classification_accuracy", "Classification Accuracy")
plot_metrics("classification_loss", "Classification Loss")

def intersection_over_union(pred_box, true_box):
    xmin_pred, ymin_pred, xmax_pred, ymax_pred = np.split(pred_box, 4, axis=1)
    xmin_true, ymin_true, xmax_true, ymax_true = np.split(true_box, 4, axis=1)
    smoothing_factor = 1e-10
    xmin_overlap = np.maximum(xmin_pred, xmin_true)
    xmax_overlap = np.minimum(xmax_pred, xmax_true)
    ymin_overlap = np.maximum(ymin_pred, ymin_true)
    ymax_overlap = np.minimum(ymax_pred, ymax_true)
    pred_box_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)
    true_box_area = (xmax_true - xmin_true) * (ymax_true - ymin_true)
    overlap_area = np.maximum((xmax_overlap - xmin_overlap), 0) * np.maximum((ymax_overlap - ymin_overlap), 0)
    union_area = (pred_box_area + true_box_area) - overlap_area
    iou = (overlap_area + smoothing_factor) / (union_area + smoothing_factor)
    return iou

predictions = model.predict(validation_digits, batch_size=64)
predicted_labels = np.argmax(predictions[0], axis=1) + 1
prediction_bboxes = predictions[1]

iou = intersection_over_union(prediction_bboxes, validation_bboxes)
iou_threshold = 0.6

def display_results(digits, predictions, labels, pred_bboxes, bboxes, iou, title):
    fig = plt.figure(figsize=(20, 4))
    plt.title(title)
    n = len(predictions)
    for i in range(n):
        ax = fig.add_subplot(1, n, i+1)
        bboxes_to_plot = []
        if i < len(pred_bboxes):
            bboxes_to_plot.append(pred_bboxes[i])
        if i < len(bboxes):
            bboxes_to_plot.append(bboxes[i])
        image_arr = digits[i].astype(np.uint8)
        if image_arr.ndim == 3 and image_arr.shape[2] == 1:
            image_arr = image_arr.squeeze(axis=2)
        img_to_draw = draw_bounding_boxes_on_image_array(image_arr,
                                                         np.asarray(bboxes_to_plot),
                                                         color=["red", "green"],
                                                         display_str_list=["True", "Pred"])
        plt.xlabel(chr(predictions[i] + 64))
        plt.ylabel(chr(labels[i] + 64))
        plt.imshow(img_to_draw)
    plt.show()

display_results(validation_digits, predicted_labels, validation_labels,
                prediction_bboxes, validation_bboxes, iou, "True and Predicted Letters")

